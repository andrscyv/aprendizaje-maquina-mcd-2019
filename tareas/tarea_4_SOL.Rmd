---
title: 'Tarea 4: regresión logística'
output:
  html_document:
    df_print: paged
---

En esta tarea construiremos varios modelos de regresión logística
y compararemos sus resultados.

### Preparación

Puedes usar el siguiente código, o tus implementaciones propias:

```{r}
source("tarea_4_codigo.R")
```

Usaremos los datos de sobrevivientes del hundimiento del Titanic,
obtenidos de [este concurso de Kaggle](https://www.kaggle.com/c/titanic)

```{r}
library(tidyverse)
datos_titanic <- read_csv("./tarea_4_datos/train.csv")
```

En este caso, queremos predecir la variable *Survived* en términos del resto.
Para simiplificar el ejericicio, 

 - solo usaremos algunas de las variables,
 - ignoramos datos faltantes en la variable edad

```{r}
datos_titanic <- datos_titanic %>% 
    select(Survived, Pclass, Age, Sex, Embarked) %>%
    filter(!is.na(Age), !is.na(Embarked))
summary(datos_titanic)
head(datos_titanic)
```

La descripción de las variables es:

survival	Survival	0 = No, 1 = Yes
pclass	Ticket class	1 = 1st, 2 = 2nd, 3 = 3rd
sex	Sex	
Age	Age in years	
embarked	Port of Embarkation	C = Cherbourg, Q = Queenstown, S = Southampton

Convertimos las variables categóricas a numerícas creando indicadoras, como
sigue:

```{r}
datos <- datos_titanic %>% 
         mutate(female = as.numeric(Sex == "female"),
                southampton = as.numeric(Embarked == "S"),
                cherbourg = as.numeric(Embarked == "C")) %>%
        select(-Embarked, -Sex)
datos
```

Consierando cómo se ven estos datos, podemos usar una normalización simple
(puedes también hacerlo como lo hicimos en clase), de forma que todas las variables
estén aproximadamente en el rango 0 - 1 :

```{r}
datos$age_n <- datos$Age / 60
datos$pclass_n <-(datos$Pclass - 1) / 3
datos_trans <- datos %>% select(Survived, pclass_n, age_n, female, southampton, cherbourg)
datos_trans
```


Y finalmente, separa en entrenamiento y prueba de esta forma (como estamos
normalizando con cantidades fijas predefinidas, no tenemos que normalizar por separado):

```{r}
set.seed(2850)
datos_trans <- datos_trans %>% 
    mutate(u = runif(nrow(datos_trans))) 
entrena <- datos_trans %>% filter(u <= 0.7) %>% select(-u)
prueba <- datos_trans %>% filter(u > 0.7) %>% select(-u)
```

Creamos matrices:

```{r}
nrow(entrena)
nrow(prueba)
x_ent <- as.matrix(entrena %>% select(-Survived))
x_pr <- as.matrix(prueba %>% select(-Survived))
y_ent <- entrena$Survived
y_pr <- prueba$Survived
```


### Ejercicio A

1. Ajusta un modelo usando solo una variable (por ejemplo, el indicador si 
abordó en Cherbourg). Ajusta el tamaño de paso y checa convergencia

```{r}
x_ent_1 <- x_ent[ , "cherbourg", drop = FALSE] # drop=false es para no convertir en vector
devianza_ent <- devianza_calc(x_ent_1, y_ent)
grad_ent <- grad_calc(x_ent_1, y_ent)
## termina estas dos líneas
num_iteraciones <- 100
eta <- 1
z <- descenso(n = num_iteraciones, c(0,0), eta = eta, grad_ent)
plot(z[,1], type = 'line')
plot(z[,2], type = 'line')
dev_iter = apply(z,MARGIN=1, FUN=devianza_ent)
plot(dev_iter)
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
x_pr_1 <-  x_pr[ , "cherbourg", drop = FALSE]
devianza_pr <- devianza_calc(x_pr_1, y_pr)
devianza_pr(z[num_iteraciones,])
```

3. Para este modelo simple, calcula la probabilidad estimada por el modelo
de sobrevivir 
para una persona que embarcó en cherbourg y una que no:

```{r}
# Rellena:
# probabilidad sobrevivir si no embarcó en Cherbourg
betas <- z[num_iteraciones, ]
h( betas[1] )
# probabilidad si embarcó  en Cherbourg
h( betas[1] + betas[2] )
```


### Ejercicio B

Ahora utiliza todas las variables, y repite el ejercicio anterior:

1. Ajusta el tamaño de paso y checa convergencia

```{r}
devianza_ent <- devianza_calc(x_ent, y_ent)
grad_ent <- grad_calc(x_ent, y_ent)
## termina estas líneas
num_iteraciones <- 800
eta <- 1
z <- descenso(n = num_iteraciones, rep(0, 6), eta = eta, grad_ent)
tail(z)
dev_iter = apply(z,MARGIN=1, FUN=devianza_ent)
plot(dev_iter)
dev_ent_original <- dev_iter[num_iteraciones]
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(x_pr, y_pr)
betas <- z[num_iteraciones, ]
devianza_pr(betas)
```

¿Qué modelo es mejor?
El que toma en cuenta mas variables

3. Calcula la probabidad estimada de que un hombre con boleto de 3a clase, de 40 años,
que abordó en southampton sobreviva. Repite para una mujer con boleto de 1a clase, de 60
años, que abordó en southampton


```{r}
names(betas) <- c("Intercept", colnames(x_ent))
betas
```

```{r}
##Hombre
prob <- h(betas[1]+0.6666667*betas[2]+0.6666667*betas[3]+betas[5] )
prob
##Mujer
prob <- h(betas[1]+betas[3]+betas[4] + betas[5])
prob
```


4. Grafica las probabilidades estimadas (del modelo) para alguien que subió en Southampton,
para todos los rangos de edad, hombres y mujeres, de las tres clases posibles. Puedes
empezar con el siguiente código:

```{r}
dat_calc <- expand.grid(list ( pclass_n = unique(x_ent[,"pclass_n"]),
                   age_n = unique(x_ent[, "age_n"]),
                   female = c(0,1),
                   southampton = 1,
                   cherbourg = 0))
mat_calc <- as.matrix(dat_calc)
dat_calc$p_surv <- p_beta(mat_calc, betas)
ggplot(dat_calc, aes(x = 60*age_n, y = p_surv, colour = factor(3 * pclass_n + 1), 
    group = pclass_n)) +
    facet_wrap(~female) + geom_line()  + ylim(c(0, 1)) +
    labs(title = "Probabilidades superviviencia (Pasajeros de Southampton)")
```

¿Cuáles son las probabilidades más altas? ¿Cuáles son las más bajas?
Las mas altas son las niñas ( edad < 20 ) de primera clase, las mas bajas son los señores de 80 años de tercera clase
5. ¿Cuál de los dos modelos anteriores (una sola variable, todas las variables)
se desempeña mejor? ¿Por qué?
El de todas las variables se desempeña mejor con el criterio de la devianza. Se podría pensar que esto se debe a que hay mayor presición de predecir una clase cuando se tiene más información relevante del sujeto

6. Calcula el error de clasificación de prueba 

```{r}
prob_pr <- p_beta(x_pr, betas)
y_pred <- as.numeric(prob_pr > 0.5)
# escribe aquí tu código
err_clasificacion_pr <- mean(as.numeric(y_pr == y_pred))
err_clasificacion_pr
```

### Ejercicio C

Ahora supondremos que tenemos algunas variables adicionales para incluir en el modelo.
En este ejercicio veremos qué sucede si estas variables **no** pueden ayudarnos
a predecir (las simulamos al azar)

Dada la escala de nuestras variables, podemos simular variables con valores entre 0 y 1

```{r}
set.seed(201)
p_ruido <- 3 # agregamos 50 variables sin información
n_ent <- nrow(x_ent)
n_pr <- nrow(x_pr)
mat_ent <- matrix(runif(n_ent * p_ruido), n_ent, p_ruido)
mat_pr <- matrix(runif(n_pr * p_ruido), n_pr, p_ruido)
##head(mat_ent)
```

1. Ajusta un modelo usando todas las variables, incluyendo
las generadas aleatoriamente:

```{r}
devianza_ent <- devianza_calc(cbind(x_ent, mat_ent), y_ent)
grad_ent <- grad_calc(cbind(x_ent, mat_ent), y_ent)
## termina esta línea
n_iter <- 1000
eta <- 0.25
z <- descenso(n = n_iter, rep(0, 6 + p_ruido), eta = eta, grad_ent)

dev_iter = apply(z,MARGIN=1, FUN=devianza_ent)
plot(dev_iter)
dev_ent_ruidosa <- dev_iter[n_iter]
```

2. Calcula ahora la devianza de prueba de este modelo

```{r}
devianza_pr <- devianza_calc(cbind(x_pr, mat_pr), y_pr)
devianza_pr(z[n_iter, ])
```

Prueba utilizando otras semillas. Contesta:

- ¿Cómo es la devianza de prueba
de el modelo con las variables ruidosas en comparación al modelo con
las seis variables originales?
Es mayor la devianza del que tiene variables ruidosas
- ¿Cómo es la devianza de entrenamiento
del modelo con las variables ruidosas en comparación al modelo con
las seis variables originales?
La devianza de entrenamiento con variables ruidosas es menor a la devianza con las variables originales
- ¿Cómo se compara la devianza de *entrenamiento* del modelo con 6 variables
con el modelo con todas las variables ruidosas?
Tiene casi una decima menos de devianza el modelo con variables ruidosas

3. Haz pruebas agregando 2 o 3 variables ruidosas. ¿Qué tan grande es la diferencia
entre la evaluación de los modelos?
Como de una centesima
¿Podría ser que el desempeño de prueba del modelo con variables ruidosas
fuera ligeramente mejor que el que no tienen variables ruidosas? ¿Por qué?
Sí puede ser mejor en devianza de entrenamiento, tal vez al tener más parámetros el modelo se puede ajustar con mayor precisión a los datos de entrenamiento, aunque esto no signifique un mejor clasificador

